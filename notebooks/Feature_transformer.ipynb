{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook containes a prototype of a Feature Transformer - it implements a preprocessing step where a number of functions are applied on the features to (hopefully) improve performance, thereby fulfilling an important part of feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "import random\n",
    "from sko.GA import GA\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms \n",
    "Transform functions that will be used in our feature engineering are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# A set of utility functions used in the features' transformers is given below\n",
    "\n",
    "# This function outputs a tuple containing the values of a given pandas Series as a numpy array and its name as a string\n",
    "def get_name(x:pd.Series) -> tuple[np.array, str]:\n",
    "    try:\n",
    "        return x.values, x.name\n",
    "    # If not a pandas Series, assume a numpy ndarray and return itself\n",
    "    except AttributeError:\n",
    "        print(\"The argument passed is not a pandas.Series\")\n",
    "        return x, \"feat\"\n",
    "\n",
    "# This is a transformation function, applying polynomial transformation of desired degree to a pandas Series or a single-column numpy array \n",
    "# and returning a pandas DataFrame\n",
    "def polynomial(x:pd.Series, degree: int) -> pd.DataFrame:\n",
    "    # print(f\"degree:  {degree}\")\n",
    "    values, col_name = get_name(x)\n",
    "    data = values ** degree\n",
    "    return pd.DataFrame(data=data, columns = [f\"{col_name} - poly-{degree}\"])\n",
    "\n",
    "# This is a transformation function, applying square root transformation to a pandas Series or a single-column numpy array, while keeping the\n",
    "# signs of the values, returning a pandas DataFrame\n",
    "def square_root(x: pd.Series) -> pd.DataFrame:\n",
    "    values, col_name = get_name(x)\n",
    "    data = np.sign(values) * np.sqrt(np.abs(values))\n",
    "    return pd.DataFrame(data=data, columns=[f\"{col_name} - sqrt\"])\n",
    "\n",
    "# This function inverses the values of a pandas Series or a single-column numpy array, while accounting for zero and keeping the signs of the \n",
    "# values, retyrning a pandas DataFrame\n",
    "def reciprocal(x: pd.Series) -> pd.DataFrame:\n",
    "    values, col_name = get_name(x)\n",
    "    data = np.sign(values) / (1 + np.abs(values))\n",
    "    return pd.DataFrame(data=data, columns=[f\"{col_name} - reciprocal\"])\n",
    "\n",
    "# This function applies Box Cox power transform to a pandas Series or a single-column numpy array, while accounting for the fact that this \n",
    "# transformation only applies for positive values, and keeping the sign. Optimal lambda value is estimated by the sklearn implementation\n",
    "# of the PowerTransformer, which includes Box Cox transformation. Returns a pandas DataFrame.\n",
    "def box_cox(x: pd.Series) -> pd.DataFrame:\n",
    "    pt = PowerTransformer(method='box-cox', standardize=False)\n",
    "    values, col_name = get_name(x)\n",
    "    data = np.sign(values).reshape(-1, 1) * pt.fit_transform(np.abs(values).reshape(-1, 1))\n",
    "    return pd.DataFrame(data=data, columns=[f\"{col_name} - box-cox\"])\n",
    "\n",
    "# This function applies Yeo-Johnson power transform to a pandas Series or a single-column numpy array. Optimal lambda value is estimated \n",
    "# by the sklearn implementation of the PowerTransformer, which includes Yeo-Johnson transformation. Returns a pandas DataFrame.\n",
    "def yeo_johnson(x:pd.Series)-> pd.DataFrame:\n",
    "    pt = PowerTransformer(method=\"yeo-johnson\", standardize=False)\n",
    "    values, col_name = get_name(x)\n",
    "    data = pt.fit_transform(values.reshape(-1, 1))\n",
    "    return pd.DataFrame(data=data, columns=[f\"{col_name} - yeo-johnson\"])\n",
    "\n",
    "# This function applies quantile transform to a pandas Series or a single-column numpy array and maps it to a uniform distribution.\n",
    "# Returns a pandas DataFrame.\n",
    "def quantile_transformation(x:pd.Series) -> pd.DataFrame:\n",
    "    qt = QuantileTransformer(random_state=0)\n",
    "    values, col_name = get_name(x)\n",
    "    data = qt.fit_transform(values.reshape(-1, 1))\n",
    "    # data = qt.fit_transform(values)\n",
    "    return pd.DataFrame(data=data, columns=[f\"{col_name} - quantile\"])\n",
    "\n",
    "# This function sets the transformations that are going to be used on our features, returns a list of lambda functions.\n",
    "def set_mapper(poly_degree:int) -> list:\n",
    "    mapper = [lambda x: square_root(x),\n",
    "              lambda x: reciprocal(x),\n",
    "              lambda x: box_cox(x),\n",
    "              lambda x: yeo_johnson(x),\n",
    "                 lambda x: x]\n",
    "\n",
    "    mapper.extend([lambda x, i=i: polynomial(x, i) for i in range(2, poly_degree + 1)])\n",
    "\n",
    "    return mapper\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic algorithm\n",
    "The code for the genetic agorithm controlling the feature transformation process is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The FeatureTransformer class applies a number of functions on the features in order to improve the linear correlation between\n",
    "# them and the target variables: linear relations are easily detected by machine learning models and can lead to significant\n",
    "# performance boost\n",
    "\n",
    "class FeatureTransformer:\n",
    "    # no_poly = 4\n",
    "\n",
    "    # df - feature DataFrame, y - target array\n",
    "    def _set_data(self, df:pd.DataFrame, y: np.array):\n",
    "        self.data = df\n",
    "        self.y = y\n",
    "\n",
    "    # Initializing the genetic algorithm, variables are self-explanatory\n",
    "    def __init__(self, size_pop=50, max_iter=200, prob_mut=0.001, df: pd.DataFrame=None, y:np.array=None, \n",
    "                 poly_degree:int=5, target_names:list=None):\n",
    "        # Making sure either both df and y are None or both are not None\n",
    "        if df is None != y is None:\n",
    "            raise ValueError(\"Make sure that that either both data and target fields are None, or none of them.\")\n",
    "\n",
    "        # Setting the data field only if the argument is explicitly passed to avoid None values\n",
    "        if df:\n",
    "            self.data = df\n",
    "            self.y = y\n",
    "\n",
    "        # Initialize a dictionary of the possible transformations to apply on the columns of the dataframe\n",
    "        self.function_mapper = set_mapper(poly_degree)\n",
    "        if target_names is None:\n",
    "            self.target_names = ['y', 'target', 'dependent_variable']\n",
    "\n",
    "        # Set the parameters for running GA\n",
    "        self.size_pop = size_pop\n",
    "        self.max_iter = max_iter\n",
    "        self.prob_mut = prob_mut\n",
    "\n",
    "        # Define a field for the latest fitted transformations\n",
    "        self.fitted_x = None \n",
    "    \n",
    "    # This function defines the way a chosen position in a chromosome is mutated, returns integer\n",
    "    @classmethod\n",
    "    def _mutation_pattern(cls, value_function, mapper):\n",
    "        # If the function is among the first 4 values (non-polynomial), map it to another non-polynomial function\n",
    "        num_functions = len(mapper)\n",
    "\n",
    "        # If the function is non-polynomial, choose a new non-polynomial fucntion\n",
    "        if value_function < 4:\n",
    "            while True:\n",
    "                new_value = random.choices(list(range(4)), k=1)[0]\n",
    "                if new_value != value_function:\n",
    "                    return new_value\n",
    "\n",
    "        # If the function is polynomial, get a random value that will determine whether to increment \n",
    "        # or decrement the degree of the polynomial function\n",
    "        increase_decrease_prob = random.random()\n",
    "        return 4 + ((value_function + (1 if increase_decrease_prob < 0.5 else -1)) % (num_functions - 4))\n",
    "\n",
    "    # This function randomly chooses a position inside a chromosome to mutate\n",
    "    def _mutation_chromosome(self, chromosome):\n",
    "        chromosome_length = len(chromosome)\n",
    "        position_to_mutate = random.randint(0, chromosome_length - 1)\n",
    "        chromosome[position_to_mutate] = self._mutation_pattern(chromosome[position_to_mutate], self.function_mapper)\n",
    "        return chromosome\n",
    "\n",
    "    # The actual function that will be called by the GA algorithm to perform mutation\n",
    "    def _ga_mutation_function(self, algorithm):\n",
    "        # According to the library's code the population is saved in a Chrom field: 2d np.array of shape (self.size_pop, self.n_dim),\n",
    "        # iterate through the population\n",
    "        for i in range(algorithm.size_pop):\n",
    "            if np.random.rand() < algorithm.prob_mut:\n",
    "                algorithm.Chrom[i] = self._mutation_chromosome(algorithm.Chrom[i])\n",
    "        \n",
    "        return algorithm.Chrom\n",
    "\n",
    "    # Ensure that there is at least one target name that is not in the feature columns of the dataframe\n",
    "    def _find_target_name(self):\n",
    "        for name in self.target_names:\n",
    "            if name not in self.data.columns:\n",
    "                target = name\n",
    "                return target\n",
    "        # Reaching this part of the code means that all the possible names to denote the target column\n",
    "        # are present in the dataframe, then raise an error\n",
    "        raise ValueError(\"All possible target names are already in use!!!\\nPlease consider adding a new target name or\"\n",
    "                         \"\\nchanging the dataframe's column names\")\n",
    "\n",
    "    # This function applies the effects of the functions defined in the chromosomes to the exiting features\n",
    "    # returns new features after the transformation\n",
    "    def _new_features(self, chromosome: np.array, df:pd.DataFrame=None):\n",
    "        if df is None:\n",
    "            df = self.data\n",
    "\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            df = pd.DataFrame(data=df, columns=range(df.shape[1]))\n",
    "        \n",
    "        # The chromosome is assumed to be a numpy array of size : number of features of the data field\n",
    "        # iterate through the chromosome: each value maps to a function\n",
    "        # apply this function on the corresponding column\n",
    "        new_features = [self.function_mapper[int(value_function)](df[d]) for d, value_function in zip(df.columns, chromosome)]\n",
    "\n",
    "        # Concatenate all the new features into a single dataframe\n",
    "        all_data =  pd.concat(new_features, axis=1, ignore_index=False)\n",
    "        \n",
    "        return all_data\n",
    "\n",
    "    # This function calculates the correlation between transformed features and the target\n",
    "    def _get_correlation(self, chromosome) -> pd.Series:\n",
    "        # Get the new features from the chromosome\n",
    "        new_features = self._new_features(chromosome)\n",
    "        \n",
    "        # Retrieve the target name\n",
    "        target_name = self._find_target_name()\n",
    "        \n",
    "        # Add the target variable's values as a column to the \"new_features\" dataframe\n",
    "        new_features[target_name] = self.y.copy()\n",
    "        \n",
    "        # Compute the correlation matrix (linear correlation)\n",
    "        linear_corr = np.abs(new_features.corr()[target_name])\n",
    "\n",
    "        # Order the columns by their correlation to the target\n",
    "        linear_corr.sort_values(ascending=False, inplace=True)\n",
    "        linear_corr.drop(target_name, inplace=True)\n",
    "        return linear_corr\n",
    "\n",
    "    # This is the function calculating fitness value of a given chromosome by measuring correlation coefficients\n",
    "    # with the target value\n",
    "    def _ga_function(self, chromosome: np.array):\n",
    "        linear_corr = self._get_correlation(chromosome)\n",
    "        # the score is the reverse of the average score of the best \"num_feats\" new features\n",
    "        return 1 / (linear_corr.mean())\n",
    "\n",
    "    # This function fits a given dataset and target column into a Genetic Algorithm object from sko library\n",
    "    def fit(self, df:pd.DataFrame, y: np.array):\n",
    "        # If the passed object is not a dataframe, it is assumed to be a numpy array\n",
    "        num_feats = df.shape[1]\n",
    "\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            df = pd.DataFrame(data=df, columns=range(num_feats))\n",
    "        \n",
    "        # Set the data fields for later use\n",
    "        self._set_data(df, y)\n",
    "\n",
    "        # Define a function object to pass to the Genetic algorithm\n",
    "        ga_function = lambda x: self._ga_function(x)\n",
    "\n",
    "        # Define the lower and upper bounds for the chromosomes\n",
    "        lower_bound = np.zeros(num_feats)\n",
    "        upper_bound = np.full(shape=(num_feats, ), fill_value=len(self.function_mapper) - 1)\n",
    "        # Define the precision so that values in chromosome objects are integers\n",
    "        precision = np.full(shape=(num_feats, ), fill_value=1)\n",
    "\n",
    "        # Define a GA object\n",
    "        ga = GA(func=ga_function, n_dim=num_feats, size_pop=self.size_pop, max_iter=self.max_iter, prob_mut=self.prob_mut,\n",
    "                lb=lower_bound, ub=upper_bound, precision=precision)\n",
    "\n",
    "        # Register the mutation operator\n",
    "        ga.register(operator_name='mutation', operator=lambda x: self._ga_mutation_function(x))\n",
    "\n",
    "        # Run the algorithm\n",
    "        best_x, best_y = ga.run()\n",
    "\n",
    "        self.fitted_x = best_x\n",
    "    \n",
    "    # This function applies the tranformations onto a given DataFrame\n",
    "    def transform(self, df:pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.fitted_x is None:\n",
    "            raise ValueError(\"The feature transformer is not fitted yet. Make sure to call FeatureTransformer.fit(X, y) beforehand\")    \n",
    "        \n",
    "        return self._new_features(self.fitted_x, df)\n",
    "    \n",
    "    # This is the main function applying the GA on a set of features and a target column,\n",
    "    # returning a dataset of transformed features\n",
    "    def fit_transform(self, df: pd.DataFrame, y: np.array) -> pd.DataFrame:\n",
    "        self.fit(df, y)\n",
    "        return self.transform(df)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Testing the GA Feature Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for dataset 0: with no transformations\n",
      "\n",
      "model: Nearest Neighbors\n",
      "accuracy: 0.905\n",
      "\n",
      "model: Linear SVM\n",
      "accuracy: 0.8675\n",
      "\n",
      "model: RBF SVM\n",
      "accuracy: 0.918125\n",
      "\n",
      "model: Decision Tree\n",
      "accuracy: 0.908125\n",
      "\n",
      "model: Random Forest\n",
      "accuracy: 0.91\n",
      "\n",
      "for dataset 0 with transformations\n",
      "\n",
      "\n",
      "model: Nearest Neighbors\n",
      "accuracy: 0.908125\n",
      "\n",
      "\n",
      "model: Linear SVM\n",
      "accuracy: 0.885\n",
      "\n",
      "\n",
      "model: RBF SVM\n",
      "accuracy: 0.92125\n",
      "\n",
      "\n",
      "model: Decision Tree\n",
      "accuracy: 0.90875\n",
      "\n",
      "\n",
      "model: Random Forest\n",
      "accuracy: 0.9075\n",
      "\n",
      "for dataset 1: with no transformations\n",
      "\n",
      "model: Nearest Neighbors\n",
      "accuracy: 0.85625\n",
      "\n",
      "model: Linear SVM\n",
      "accuracy: 0.5375\n",
      "\n",
      "model: RBF SVM\n",
      "accuracy: 0.885625\n",
      "\n",
      "model: Decision Tree\n",
      "accuracy: 0.8575\n",
      "\n",
      "model: Random Forest\n",
      "accuracy: 0.860625\n",
      "\n",
      "for dataset 1 with transformations\n",
      "\n",
      "\n",
      "model: Nearest Neighbors\n",
      "accuracy: 0.868125\n",
      "\n",
      "\n",
      "model: Linear SVM\n",
      "accuracy: 0.886875\n",
      "\n",
      "\n",
      "model: RBF SVM\n",
      "accuracy: 0.889375\n",
      "\n",
      "\n",
      "model: Decision Tree\n",
      "accuracy: 0.870625\n",
      "\n",
      "\n",
      "model: Random Forest\n",
      "accuracy: 0.885\n",
      "\n",
      "for dataset 2: with no transformations\n",
      "\n",
      "model: Nearest Neighbors\n",
      "accuracy: 0.894375\n",
      "\n",
      "model: Linear SVM\n",
      "accuracy: 0.906875\n",
      "\n",
      "model: RBF SVM\n",
      "accuracy: 0.915625\n",
      "\n",
      "model: Decision Tree\n",
      "accuracy: 0.901875\n",
      "\n",
      "model: Random Forest\n",
      "accuracy: 0.91375\n",
      "\n",
      "for dataset 2 with transformations\n",
      "\n",
      "\n",
      "model: Nearest Neighbors\n",
      "accuracy: 0.888125\n",
      "\n",
      "\n",
      "model: Linear SVM\n",
      "accuracy: 0.90875\n",
      "\n",
      "\n",
      "model: RBF SVM\n",
      "accuracy: 0.903125\n",
      "\n",
      "\n",
      "model: Decision Tree\n",
      "accuracy: 0.89875\n",
      "\n",
      "\n",
      "model: Random Forest\n",
      "accuracy: 0.9075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    # \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    # \"Neural Net\",\n",
    "    # \"AdaBoost\",\n",
    "    # \"Naive Bayes\",\n",
    "    # \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    # GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    # MLPClassifier(alpha=1, max_iter=1000),\n",
    "    # AdaBoostClassifier(),\n",
    "    # GaussianNB(),\n",
    "    # QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=4000, n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1\n",
    ")\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [\n",
    "    make_moons(n_samples=4000, noise=0.3, random_state=0),\n",
    "    make_circles(n_samples=4000, noise=0.2, factor=0.5, random_state=1),\n",
    "    linearly_separable,\n",
    "]\n",
    "\n",
    "with open('../test_results/test_transformer.txt', 'a') as f:\n",
    "    for ds_cnt, ds in enumerate(datasets):\n",
    "        # preprocess dataset, split into training and test part\n",
    "        X, y = ds\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.4, random_state=42\n",
    "        )\n",
    "        \n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(f\"for dataset {ds_cnt} :\\n\")\n",
    "        \n",
    "        print()\n",
    "        print(f\"for dataset {ds_cnt}: with no transformations\")\n",
    "        \n",
    "        for name, clf in zip(names, classifiers):\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            f.write(\"\\n\\n\")\n",
    "            f.write(f\"model: {name}\\n\")\n",
    "            f.write(f\"accuracy: {score}\\n\")\n",
    "\n",
    "            print()\n",
    "            print(f\"model: {name}\")\n",
    "            print(f\"accuracy: {score}\")\n",
    "\n",
    "        # add feature transformations\n",
    "        # create the feature transformer\n",
    "        transformer = FeatureTransformer()\n",
    "        X, y = ds\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.4, random_state=42\n",
    "        )\n",
    "\n",
    "        X_train = transformer.fit_transform(X_train, y_train)\n",
    "        X_test = transformer.transform(X_test)\n",
    "        \n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(f\"for dataset {ds_cnt} with transformations:\\n\")\n",
    "\n",
    "        print()\n",
    "        print(f\"for dataset {ds_cnt} with transformations\")\n",
    "        for name, clf in zip(names, classifiers):\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            f.write(\"\\n\\n\")\n",
    "            f.write(f\"model: {name}\\n\")\n",
    "            f.write(f\"accuracy: {score}\\n\")\n",
    "\n",
    "            print(\"\\n\")\n",
    "            print(f\"model: {name}\")\n",
    "            print(f\"accuracy: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def _get_new_df(self, chromosome):\n",
    "    #     num_feats = self.data.shape[1]\n",
    "    #     new_features = self._new_features(chromosome)\n",
    "    #     target_var = self._find_target_name()\n",
    "\n",
    "    #     correlation = new_features.corr()[target_var]\n",
    "    #     correlation.sort_values(ascending=False, inplace=True)\n",
    "    #     # make sure to remove the 'target_variable' from the correlation\n",
    "    #     correlation.drop('y', inplace=True)\n",
    "    #     return new_features.loc[:, list(correlation.iloc[:num_feats].index)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de47f5c92c0ee6f12a59a5613ac5feff6aab19ddff207ba0b3964cced08c4ccc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
